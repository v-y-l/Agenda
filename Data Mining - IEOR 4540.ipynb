{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1VhRANga1rES",
        "ZRHox2gLfZjr",
        "Rv3knyOqDEr1",
        "tLpt4exQFmF_",
        "2gzAv-CxoYKn",
        "AcxB_jYvoTIt",
        "qHItLzITyePc",
        "deiVRpArp22G"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/v-y-l/Agenda/blob/master/Data%20Mining%20-%20IEOR%204540.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3\n",
        "\n",
        "**Problem 3: Linearization of the feedforward layers in Neural Networks**\n",
        "\n",
        "Consider a feedforward layer of the following form, where $\\mathbf{W} \\in \\mathbb{R}^{d \\times d}, \\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^d$ :\n",
        "$$\n",
        "\\mathbf{y}=f(\\mathbf{W} \\mathbf{x})                        \n",
        "$$\n",
        "\n",
        "Assume that $f$ is a GELU function. Propose an algorithm to approximate it via the following \"linearized variant\", where $\\Phi: \\mathbb{R}^{d \\times d} \\rightarrow \\mathbb{R}^{d \\times m}, \\Psi: \\mathbb{R}^d \\rightarrow \\mathbb{R}^m$ are some functions (to be constructed by you):\n",
        "$$\n",
        "\\mathbf{y}^{\\prime}=\\Phi(\\mathbf{W}) \\Psi(\\mathbf{x}) .\n",
        "$$\n",
        "\n",
        "The approximation does not need to be unbiased. Can you propose the unbiased variant ?\n"
      ],
      "metadata": {
        "id": "PWnbBNiCt8Fj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jicheol, Lisa, Victor: Context"
      ],
      "metadata": {
        "id": "1VhRANga1rES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a synthetic dataset\n"
      ],
      "metadata": {
        "id": "ZRHox2gLfZjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from scipy.special import erf"
      ],
      "metadata": {
        "id": "hzOloJ1pilvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Choosing d = 10 so we can see meaningful interactions between features\n",
        "# via weights, but small enough to visualize and run efficient experiments.\n",
        "d = 10\n",
        "\n",
        "# Don't use np.random.rand(d, 1), which doesn't consider negatives since it\n",
        "# takes a uniform distribution of [0,1]. Our dataset should consider negatives,\n",
        "# since gelu accepts them.\n",
        "#\n",
        "# Mean = 0, std dev = 1 should be fine, since most inputs are normalized anyway.\n",
        "x = np.random.normal(loc=0, scale=1, size=(d, 1))\n",
        "print(\"Layer shape of x: \", x.shape)\n",
        "print(x)\n",
        "\n",
        "\n",
        "W = np.random.normal(loc=0, scale=1, size=(d, d))\n",
        "print(\"Layer shape of W: \", W.shape)\n",
        "print(W)\n"
      ],
      "metadata": {
        "id": "j4ZMiF8MKjjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3502c22f-5047-4e8e-e9da-2238c66f697f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer shape of x:  (10, 1)\n",
            "[[ 1.50427133]\n",
            " [ 0.12883938]\n",
            " [ 2.25638834]\n",
            " [ 0.88788649]\n",
            " [ 1.08481095]\n",
            " [ 1.45251453]\n",
            " [-0.53818156]\n",
            " [-0.49495873]\n",
            " [-0.26553295]\n",
            " [ 0.05059396]]\n",
            "Layer shape of W:  (10, 10)\n",
            "[[ 1.66975456  0.52391017  0.63067868 -0.05602936 -0.41535352  1.56239377\n",
            "  -0.52607486 -0.52445412  0.19798323 -1.54899586]\n",
            " [ 1.67165437  2.09326596 -0.1202136  -2.49351689 -0.86552997  0.23419346\n",
            "  -0.74472836  0.49668319 -1.69102042 -0.22994001]\n",
            " [ 1.15991586  0.54098766 -1.12550547 -0.08318706  0.66258887  1.13547324\n",
            "   0.58006594  1.65811478 -0.13611404  0.3619377 ]\n",
            " [ 0.23079591 -1.44466371  0.22468241  0.2947248   0.89686078 -0.29632867\n",
            "   0.6431502   1.10552663  0.17947478 -1.16208568]\n",
            " [ 0.27857126  0.97351403  1.30013342 -0.55359863  0.43286264 -0.52946618\n",
            "  -1.21382828  0.1856267   0.39737849 -0.17268367]\n",
            " [-0.84699473  0.59677227  1.62965161  0.52783984 -0.84032197  2.03213274\n",
            "  -1.29475423  2.12160854  1.7596552  -0.07258691]\n",
            " [-1.23906294 -0.96370007 -1.19646823  0.98765085  1.04996262 -1.6940743\n",
            "   0.63280704 -1.06947633 -0.02094411 -1.04603889]\n",
            " [ 0.53878288 -0.24006146 -0.89339336 -0.4842041   0.2486608   1.0145981\n",
            "  -1.48580557  0.51799251  0.13029898  0.80405737]\n",
            " [ 0.7279246  -0.75535455  1.99655852  0.68670539 -1.06282935  0.45617879\n",
            "  -0.53509558 -1.32204411  0.50022913 -0.24743772]\n",
            " [ 0.73408477 -0.78607151  0.26296502  0.37228494  0.80460231 -0.39733941\n",
            "  -0.54688191 -2.6707418  -0.8280928  -0.08018259]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.matmul(W, x)\n",
        "print(\"Layer shape of y: \", y.shape)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4vx-_ImqLhZ",
        "outputId": "7b857a18-bf25-4cc7-c8ef-b9f695bb317f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer shape of y:  (10, 1)\n",
            "[[ 6.18315814]\n",
            " [ 0.29269077]\n",
            " [ 0.49074109]\n",
            " [ 0.47243311]\n",
            " [ 3.13419227]\n",
            " [ 4.16446378]\n",
            " [-4.99106139]\n",
            " [ 0.62658407]\n",
            " [ 6.41903159]\n",
            " [ 4.05464171]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GELU through tanh\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-wLkpEvCpR7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tanh approximation\n",
        "def gelu_tanh(x):\n",
        "    return 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * x**3)))"
      ],
      "metadata": {
        "id": "Dd7JcVJjoDYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# erf approximation\n",
        "def gelu_erf(x):\n",
        "    return 0.5 * x * (1 + erf(x/np.sqrt(2)))"
      ],
      "metadata": {
        "id": "LexK1lC7jBRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## True Value of GELU"
      ],
      "metadata": {
        "id": "HfhP9RESopge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Given $W$ ∈ $\\mathbb{R}^{d\\times d}$, $x$, $y$ ∈ $\\mathbb{R}^{d}$, another way to approximate is using CDF:\n",
        "\n",
        "$GELU(x)$ = $x$ $P(X <= x)$ = $x {\\Phi}(x)$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DpnjAS6Oea2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This section is synonymous to tanh approximation, but using CDF instead. We are using the definition of GELU to set as a standard.\n",
        "#CDF is the cumulative distribution function for finding area under a standard normal function.\n",
        "\n",
        "from scipy.stats import norm\n",
        "phi_x = norm.cdf(y)\n",
        "print(\"shape of phi_x: \", phi_x.shape)\n",
        "print(\"phi_x: \", phi_x)\n",
        "\n",
        "GELU_x = y * phi_x\n",
        "print(\"shape of GELU_x: \", GELU_x.shape)\n",
        "print(\"GELU_x: \", GELU_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Fdb_2GhX5fZ",
        "outputId": "ebe334e9-cf81-423c-80b4-b90d79f83d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of phi_x:  (10, 1)\n",
            "phi_x:  [[1.00000000e+00]\n",
            " [6.15120739e-01]\n",
            " [6.88195210e-01]\n",
            " [6.81691163e-01]\n",
            " [9.99138361e-01]\n",
            " [9.99984396e-01]\n",
            " [3.00242029e-07]\n",
            " [7.34534042e-01]\n",
            " [1.00000000e+00]\n",
            " [9.99974894e-01]]\n",
            "shape of GELU_x:  (10, 1)\n",
            "GELU_x:  [[ 6.18315814e+00]\n",
            " [ 1.80040165e-01]\n",
            " [ 3.37725669e-01]\n",
            " [ 3.22053477e-01]\n",
            " [ 3.13149173e+00]\n",
            " [ 4.16439879e+00]\n",
            " [-1.49852640e-06]\n",
            " [ 4.60247328e-01]\n",
            " [ 6.41903159e+00]\n",
            " [ 4.05453992e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Below we show our biased approximation for a Taylor Series Expansion:**"
      ],
      "metadata": {
        "id": "Rv3knyOqDEr1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "let\n",
        "$f(x)= \\frac{1}{{\\sqrt {2\\pi } }}e^{ - \\frac{{z^2 }}{2}} = .3989e^{ - 5z^2 }$ be the standard normal density function and\n",
        "\n",
        "let\n",
        "$F(x)={\\frac{1}{\\sqrt{2\\pi}}}\\int_{-\\infty }^{x}e^{-t^{2}/2}\\,dt $\n",
        "be the standard normal cumulative distribution function\n",
        "\n",
        "We compute a Taylor series expansion:\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "G(x) & =\\int \\frac{1}{\\sqrt{2 \\pi}} e^{\\frac{-1}{2} x^2} d x \\\\\n",
        "& =\\frac{1}{\\sqrt{2 \\pi}} \\int \\sum_{n=0}^{\\infty} \\frac{(-1)^n}{n!2^n} x^{2 n} d x \\\\\n",
        "& =\\frac{1}{\\sqrt{2 \\pi}} \\sum_{n=0}^{\\infty} \\frac{(-1)^n}{n!2^n(2 n+1)} x^{2 n+1} \\\\\n",
        "& =\\frac{1}{\\sqrt{2 \\pi}}\\left(x-\\frac{1}{6} x^3+\\frac{1}{40} x^5-\\frac{1}{336} x^7+\\cdots\\right)\n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "\n"
      ],
      "metadata": {
        "id": "YyaOevDIhLM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Fix the +0.5 to the function and multiply by x\n",
        "\n",
        "def gelu_taylor_basic(x):\n",
        "  leading_coefficient = 1/math.sqrt(2*math.pi)\n",
        "  term1 = leading_coefficient * (x)\n",
        "  term2 = -leading_coefficient * (x**3)/6\n",
        "  term3 = leading_coefficient * (x**5)/40\n",
        "  term4 = -leading_coefficient * (x**7)/336\n",
        "  term5 = leading_coefficient * (x**9)/2480\n",
        "  term6 = -leading_coefficient * (x**11)/40320\n",
        "  term7 = leading_coefficient * (x**13)/6227040\n",
        "  return x*(0.5 + term1 + term2 + term3 + term4)\n",
        "\n",
        "#Taylor approximation using n terms, recursion\n",
        "def gelu_taylor_recursive(x, n):\n",
        "  leading_coefficient = 1/math.sqrt(2*math.pi)\n",
        "  if n == 0:\n",
        "    #first term means that there is only x\n",
        "    #this is the base case\n",
        "    return 0.5+leading_coefficient *((-1)**n) * (x**(2*n+1))/(math.factorial(n)*(2**n)*(2*n+1))\n",
        "  else:\n",
        "    #Recursion step, adding terms iteratively\n",
        "    return gelu_taylor_recursive(x, n-1) + leading_coefficient * (-1)**n / (math.factorial(n) * (2**n) * (2*n+1)) * x**(2*n+1)\n",
        "\n",
        "# Taylor approximation using n terms, for-loop\n",
        "def gelu_taylor(x,n):\n",
        "  leading_coefficient = 1/np.sqrt(2*np.pi)\n",
        "  sum = 0\n",
        "  for i in range(n):\n",
        "    sum += (-1)**i / (math.factorial(i)* (2**i) * (2*i+1)) * x**(2*i+1)\n",
        "  return x * (0.5+leading_coefficient*sum)"
      ],
      "metadata": {
        "id": "b5rbHny9kiN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample input\n",
        "\n",
        "x = 0.5\n",
        "n = 100\n",
        "print(\"Tanh approximation: \", gelu_tanh(x))\n",
        "print(\"Erf approximation: \", gelu_erf(x))\n",
        "print(\"Taylor polynomial: \", gelu_taylor(x,n))\n",
        "print(\"Base case Taylor polynomial: \", gelu_taylor_basic(x)) # Adding terms by brute force\n",
        "print(\"Taylor polynomial, recursive case\", x * gelu_taylor_recursive(x,n)) #need to multiply by x because of the function is taylor of standard normal cdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40L_MrmC-0N5",
        "outputId": "a7b3dd32-37b7-4b20-ba9c-feb52c2d979a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tanh approximation:  0.34571400982514394\n",
            "Erf approximation:  0.3457312306370065\n",
            "Taylor polynomial:  0.34573123063700656\n",
            "Base case Taylor polynomial:  0.3457311201736166\n",
            "Taylor polynomial, recursive case 0.3457312306370065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Activation functions show similar trends across five approximations**"
      ],
      "metadata": {
        "id": "tLpt4exQFmF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(-5, 5, 1000)\n",
        "\n",
        "plt.figure(figsize = (10,6))\n",
        "plt.plot(x, gelu_tanh(x), label='GELU (tanh)')\n",
        "plt.plot(x, gelu_erf(x), label='GELU (erf)', linestyle='--')\n",
        "plt.plot(x, gelu_taylor(x,100), label='GELU (taylor)', linestyle='-')\n",
        "plt.plot(x, x*gelu_taylor_recursive(x, 100), label='GELU (taylor_recursive)')\n",
        "#plt.plot(x, [gelu_MC(i,100) for i in x], label='GELU (MC)', linestyle='-')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('GELU(x)')\n",
        "plt.legend(['Tanh approximation', 'erf approximation', 'Taylor approximation', 'Taylor recursive approximation', 'Monte Carlo approximation'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Q4JArVoD9P_-",
        "outputId": "00708edc-e985-4d17-9856-e9cbdc346bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Victor: **Phi and psi for GELU Taylor Series approximation (biased estimation)**"
      ],
      "metadata": {
        "id": "2gzAv-CxoYKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the GELU Taylor Series approximation for decomposition into phi and psi\n",
        "\n",
        "GELU is an element-wise activation function.\n",
        "\n",
        "Let the first transformed dimension be $x_1' = W_1x'$. The first row of $W$ is applied to $x$ to produce $x'$.\n",
        "\n",
        "By working out $\\phi$ and $\\psi$ for $x_1'$, we can expand it to all dimensions of $x$ wlog.\n",
        "\n",
        "Approximating GELU using Taylor series = $\\frac{x_1'}{2} + \\frac{x_1'}{2\\pi}\\sum_{n=0}^{\\infty}\\frac{(-1)^n}{n!(2n+1)}x_1'^{2n+1}\n",
        "= \\frac{x_1'}{2} + \\frac{(x_1')^2}{\\sqrt{2\\pi}} - \\frac{(x_1')^4}{6\\sqrt{2\\pi}} + \\frac{(x_1')^6}{40\\sqrt{2\\pi}} - \\frac{(x_1')^8}{336\\sqrt{2\\pi}} + ...$\n",
        "\n",
        "Notice that once expanded, the approximation takes the form\n",
        "$a_0(W_1x) + a_1(W_1x)^2 + a_2(W_1x)^4 + ...$\n"
      ],
      "metadata": {
        "id": "ui5K3mHM0bGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining phi and psi\n",
        "\n",
        "Each term in the GELU approximation is an exponentiated dot product, that once expanded, can be decomposed into phi and psi using Kronecker products.\n",
        "\n",
        "\n",
        "### First term\n",
        "\n",
        "This is easiest to understand by examing the first term:\n",
        "\n",
        "* $a_1(\\sum_{i=1}^{d}w_ix_i)^2$ = $\\sum_{i=1}^{d}\\sum_{j=1}^{d}(W_i W_j x_i x_j$), where $d$ is the of dimensions of $x$.\n",
        "\n",
        "For example, when $d = 2$,  $a_0\\sum_{i=1}^{2}\\sum_{j=1}^{2}(W_i W_j x_i x_j) = w_1^2x_1^2 + w_1w_2x_1x_2 + w_2w_1x_2x_1 + w_2^2x_2^2$.\n",
        "\n",
        "Which can be written as a dot of:\n",
        "\n",
        "$\\begin{pmatrix}\n",
        "w_1^2 &&\n",
        "w_1w_2 &&\n",
        "w_2w_1 &&\n",
        "w_2 ^2\n",
        "\\end{pmatrix} \\begin{pmatrix} x_1^2 \\\\\n",
        "x_1x_2 \\\\\n",
        "x_2x_1 \\\\\n",
        "x_2 ^2 \\end{pmatrix}$\n",
        "\n",
        "\n",
        "The left side is a Cartesian combination of $W_1$ to itself. The right side is the Cartesian combination of $x$ to itself.\n",
        "\n",
        "$a_1(\\sum_{i=1}^{d}w_ix_i)^2 = a_1*(W  \\otimes W) (x \\otimes x)^T.$\n",
        "\n",
        "### Second term\n",
        "\n",
        "If we apply the same logic, we see that:\n",
        "\n",
        "$a_2(\\sum_{i=1}^{d}w_ix_i)^4 = a_1*(W  \\otimes W \\otimes W \\otimes W) (x \\otimes x \\otimes x \\otimes x)^T$"
      ],
      "metadata": {
        "id": "BJXn9RG5lD0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generalization\n",
        "$a_n \\left(\\sum_{i=1}^d w_i x_i\\right)^{2n} = a_n \\Big( W^{\\otimes 2n} \\Big) \\cdot \\Big( x^{\\otimes 2n} \\Big)^T$, where $n$ is the term."
      ],
      "metadata": {
        "id": "velATGVGoL-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation: The 5-term Taylor Series approximation as phi and psi\n",
        "\n",
        "### 5-term Taylor series approximaton range\n",
        "\n",
        "This shows us that the $x'$ should be within $[3, 3]$ in our demonstration.\n",
        "\n",
        "\\begin{array}{|c|c|}\n",
        "\\hline\n",
        "\\text{Range of }Wx & \\text{Max Error} \\\\\n",
        "\\hline\n",
        "[-1,1]   & 9\\times10^{-6}        \\\\\n",
        "[-3,3]   & 3.0                   \\\\\n",
        "[-5,5]   & 7.8\\times10^{2}       \\\\\n",
        "[-7,7]   & 2.7\\times10^{4}       \\\\\n",
        "\\hline\n",
        "\\end{array}\n"
      ],
      "metadata": {
        "id": "69CrNmX6eauM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate dataset to stay within range of 'good' accuracy\n",
        "import numpy as np\n",
        "x = np.array([1,.1,2])\n",
        "W = np.array([\n",
        "    [-0.8, -0.8, -0.8],\n",
        "    [.5, .5, .5],\n",
        "    [.2, .3, 1]\n",
        "])\n",
        "x_prime = W @ x\n",
        "print(\"x_prime = Wx = \", x_prime)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OanMrVT7t5UJ",
        "outputId": "4e7301f7-8c71-4633-ecc5-00d7e38cf270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_prime = Wx =  [-2.48  1.55  2.23]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "class TaylorSeriesGeluEstimator:\n",
        "    def __init__(self, n_terms):\n",
        "        self.n = n_terms\n",
        "        self.coeffs = self._compute_coeffs()\n",
        "        # exponents for the monomials: [1, 2, 4, 6, …, 2n]\n",
        "        self.powers = [1] + [2*i + 2 for i in range(self.n)]\n",
        "\n",
        "    def _compute_coeffs(self):\n",
        "        \"\"\" Gathers the Taylor‐series coefficients [0.5, …] up through n_terms. \"\"\"\n",
        "        coeffs = [0.5]\n",
        "        base = 1 / math.sqrt(2 * math.pi)\n",
        "        for i in range(self.n):\n",
        "            c = (-1)**i / (math.factorial(i) * (2**i) * (2*i + 1))\n",
        "            coeffs.append(base * c)\n",
        "        return coeffs\n",
        "\n",
        "    def _kron_n(self, vec, times):\n",
        "        \"\"\" Compute vec ⨂ vec ⨂ … ⨂ vec (times times). \"\"\"\n",
        "        out = vec\n",
        "        for _ in range(times - 1):\n",
        "            out = np.kron(out, vec)\n",
        "        return out\n",
        "\n",
        "    def transform(self, vec, coeffs=None):\n",
        "        \"\"\"\n",
        "        Build a single feature vector:\n",
        "          [ coeffs[0] * vec^1, coeffs[1] * vec^2, coeffs[2] * vec^4, … ]\n",
        "        If coeffs is None, we assume all 1’s (for ψ).\n",
        "        \"\"\"\n",
        "        if coeffs is None:\n",
        "            coeffs = [1.0] * len(self.powers)\n",
        "\n",
        "        parts = []\n",
        "        for c, p in zip(coeffs, self.powers):\n",
        "            parts.append(c * self._kron_n(vec, p))\n",
        "        return np.concatenate(parts)\n",
        "\n",
        "    def get_phi(self, W):\n",
        "        \"\"\"\n",
        "        W: 2‑D array of shape (n_rows, d).\n",
        "        Returns φ of shape (n_rows, feature_dim).\n",
        "        \"\"\"\n",
        "        rows = [self.transform(w, self.coeffs) for w in W]\n",
        "        return np.vstack(rows)\n",
        "\n",
        "    def get_psi(self, x):\n",
        "        \"\"\"\n",
        "        x: 1‑D vector of length d.\n",
        "        Returns ψ of shape (feature_dim,), with no Taylor weights.\n",
        "        \"\"\"\n",
        "        return self.transform(x, coeffs=None)\n",
        "\n",
        "estimator = TaylorSeriesGeluEstimator(n_terms=5)\n",
        "phi = estimator.get_phi(W)\n",
        "psi = estimator.get_psi(x)\n",
        "phi_dot_psi = phi.dot(psi)"
      ],
      "metadata": {
        "id": "pOvulV2lBvDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class GELUComparator:\n",
        "\n",
        "  def __init__(self, n):\n",
        "    self.n = n\n",
        "\n",
        "  # Tanh approximation of Wx\n",
        "  def gelu_tanh(self, x):\n",
        "      return 0.5 * x * (1 + np.tanh(np.sqrt(2/np.pi) * (x + 0.044715 * np.power(x, 3))))\n",
        "\n",
        "  # GELU approximation of Wx using n terms\n",
        "  def gelu_taylor(self, x):\n",
        "    n = self.n\n",
        "    leading_coefficient = 1/np.sqrt(2*np.pi)\n",
        "    sum = 0\n",
        "    for i in range(n):\n",
        "      sum += (-1)**i / (math.factorial(i)* (2**i) * (2*i+1)) * x**(2*i+1)\n",
        "    return x * (0.5+leading_coefficient*sum)\n",
        "\n",
        "  def get_error(self, actual, expected):\n",
        "    return np.sqrt(np.mean((actual - expected)**2))\n",
        "\n",
        "  def compare_gelu(self, x_prime, phi_dot_psi):\n",
        "    n = self.n\n",
        "    print(\"==== Tanh VS Taylor Series ({0} terms) ====\\n\".format(n))\n",
        "\n",
        "    actual_gelu_taylor = self.gelu_taylor(x_prime)\n",
        "    expected_tanh = self.gelu_tanh(x_prime)\n",
        "    print(\"x_prime = Wx = \", x_prime)\n",
        "    print(\"gelu_taylor_{0}(x_prime) = {1}\".format(n, actual_gelu_taylor))\n",
        "    print(\"phi_dot_psi: \", phi_dot_psi)\n",
        "    print(\"gelu_tanh(x_prime) = \", expected_tanh)\n",
        "\n",
        "    error = self.get_error(actual_gelu_taylor, expected_tanh)\n",
        "    error_phi_dot_psi = self.get_error(actual_gelu_taylor, phi_dot_psi)\n",
        "    print(\"\\nError of GELU n = {0} against tanh: {1}\".format(n, error))\n",
        "    print(\"\\nError of phi_dot_psi against GELU n = {0}: {1}\".format(n,\n",
        "                                                            error_phi_dot_psi))\n",
        "\n",
        "GELUComparator(5).compare_gelu(x_prime, phi_dot_psi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po2HhyFMuGIN",
        "outputId": "7b6de7d7-1f25-449c-f078-05b86573e15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== Tanh VS Taylor Series (5 terms) ====\n",
            "\n",
            "x_prime = Wx =  [-2.48  1.55  2.23]\n",
            "gelu_taylor_5(x_prime) = [0.33582152 1.45766421 2.30608443]\n",
            "phi_dot_psi:  [0.33582152 1.45766421 2.30608443]\n",
            "gelu_tanh(x_prime) =  [-0.01585868  1.45591211  2.20158061]\n",
            "\n",
            "Error of GELU n = 5 against tanh: 0.2118199525143093\n",
            "\n",
            "Error of phi_dot_psi against GELU n = 5: 9.809465989410858e-15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Victor: Unbiased estimation using neural networks"
      ],
      "metadata": {
        "id": "4Crw0r59IRWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Big idea: we train one big model that connects phi and psi only at the\n",
        "# final node, so we can easily remove the final node (to get our phi and psi),\n",
        "# return the final node in inference basically.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# 1. Data generation: GELU dataset\n",
        "class GeluDataset(Dataset):\n",
        "    def __init__(self, N, d):\n",
        "        # PyTorch gets us to focus on shape, and we do the transformations\n",
        "        # ourselves if we want to shift\n",
        "        #\n",
        "        # Each x gets its own W\n",
        "        self.W = torch.randn(N, d, d)\n",
        "        self.x = torch.randn(N, d)\n",
        "        # In other words: Z[b, i] = sum_j (W[b, i, j] * x[b, j])\n",
        "        #\n",
        "        # 'bj -> bi' is a compact way to express which dimension (j) to dot over.\n",
        "        # 'bi' is the destination shape: one output per i, for each example b.\n",
        "        # We're summing over 'j' — which corresponds to W's columns — to merge it away.\n",
        "        Z = torch.einsum('bij,bj->bi', self.W, self.x)\n",
        "        self.y = 0.5 * Z * (1 + torch.erf(Z / math.sqrt(2)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.W[idx], self.x[idx], self.y[idx]\n",
        "\n",
        "# 2. Ψ-network: x -> m features\n",
        "class PsiNet(nn.Module):\n",
        "    def __init__(self, d, m, hidden=64):\n",
        "        super().__init__()\n",
        "        # Visaully, a line of nodes\n",
        "        self.net = nn.Sequential(\n",
        "            # Learn a bunch of numbers: project input x ∈ ℝᵈ into a hidden space.\n",
        "            # If d < hidden, we're expanding — giving the network more room to model patterns.\n",
        "            # If d > hidden, we're compressing — forcing the network to extract essentials.\n",
        "            # In both cases, hidden=64 implicitly says: \"64 features is the sweet spot\" for representing each example.\n",
        "            nn.Linear(d, hidden),\n",
        "            # max(0, x) makes the network nonlinear — it breaks additivity and homogeneity.\n",
        "            # That means we can no longer collapse it into one big linear transformation.\n",
        "            #\n",
        "            # Now, the network becomes a series of \"maybe this, not that\" filters.\n",
        "            # At each layer, ReLU adds a hard yes/no — some signals don’t make it through.\n",
        "            nn.ReLU(),\n",
        "            # arbitrarily say m is the perfect ending\n",
        "            nn.Linear(hidden, m)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# 3. Φ-network: W -> d × m matrix (row-wise MLP)\n",
        "# d is not example's d, it's batch-aware, see\n",
        "#         ψ = psi(xb)                      # (B, m)\n",
        "#Φ = phi(Wb)\n",
        "class PhiNet(nn.Module):\n",
        "    def __init__(self, d, m, hidden=64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(d, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, m)\n",
        "        )\n",
        "\n",
        "    # we learnt for all W, but apply it independently to each W\n",
        "    def forward(self, W):\n",
        "        B, D, _ = W.shape\n",
        "        W_flat = W.reshape(B * D, D)\n",
        "        out_flat = self.net(W_flat)            # (B*D, m)\n",
        "        return out_flat.view(B, D, -1)         # (B, d, m)\n",
        "\n",
        "# Hyperparameters\n",
        "d, m, N, batch_size, epochs = 2, 16, 1024, 64, 5\n",
        "\n",
        "# Prepare DataLoader\n",
        "dataset = GeluDataset(N, d)\n",
        "loader  = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Instantiate models.\n",
        "psi = PsiNet(d, m)\n",
        "phi = PhiNet(d, m)\n",
        "\n",
        "# Optimizer & loss\n",
        "optimizer = torch.optim.Adam(list(psi.parameters()) + list(phi.parameters()), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, epochs+1):\n",
        "    total_loss = 0.0\n",
        "    for Wb, xb, yb in loader:\n",
        "        optimizer.zero_grad()\n",
        "        # we feed phi and psi batches - basically back to back into one row\n",
        "        # once the object is declared, it assumes minibatches when you call obj(minibatch), and updates the underlying nodes\n",
        "        ψ = psi(xb)                      # (B, m)\n",
        "        Φ = phi(Wb)                      # (B, d, m)\n",
        "\n",
        "        # PyTorch builds one big comp graph for the forward pass,\n",
        "        # joining the two nets. Mini-batch also useful for speed.\n",
        "        #\n",
        "        # bmm is batch matrix mult, 3d to 3d; add dummy axis then remove\n",
        "        # TODO(vyl): convert to einsum, prefer that\n",
        "        y_pred = torch.bmm(Φ, ψ.unsqueeze(-1)).squeeze(-1)  # (B, d)\n",
        "\n",
        "        # Under the hood, each nn.Module (my two nets) registers its own weights\n",
        "        # as nn.Parameter, and PyTorch’s autograd links them into one big\n",
        "        # computation graph.\n",
        "\n",
        "        # When I backprop, every parameter’s .grad is filled\n",
        "        loss = criterion(y_pred, yb)\n",
        "        loss.backward()\n",
        "        # When I step, the optimizer loops over them all to the update rule.\n",
        "        #     optimizer.step() actually updates phi and psi using loss\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * Wb.size(0)\n",
        "\n",
        "      # Key insight: under the hood, PyTorch builds a computation graph.\n",
        "      # So we can write code declaratively — just describe what happens.\n",
        "      # During .backward(), PyTorch walks the graph in reverse and computes gradients.\n",
        "        #         ψ = psi(xb)         # → Tensor with attached grad_fn\n",
        "        # Φ = phi(Wb)         # → Another Tensor with grad_fn\n",
        "        # y_pred = bmm(Φ, ψ)  # → Graph combines both paths\n",
        "        # loss = criterion(y_pred, yb)\n",
        "    print(f\"Epoch {epoch}: MSE = {total_loss / N:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tSiY-i9Rcjk",
        "outputId": "b4cdd316-f904-414a-f797-7ba4b6e938be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: MSE = 0.8069\n",
            "Epoch 2: MSE = 0.3371\n",
            "Epoch 3: MSE = 0.1785\n",
            "Epoch 4: MSE = 0.1396\n",
            "Epoch 5: MSE = 0.1193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing this...\n",
        "\n",
        "import numpy as np\n",
        "def gelu_tanh(x):\n",
        "    return 0.5 * x * (1 + np.tanh(np.sqrt(2/np.pi) * (x + 0.044715 * np.power(x, 3))))\n",
        "\n",
        "# Inference on a new pair\n",
        "with torch.no_grad():\n",
        "    W_test = torch.randn(1, d, d)\n",
        "    x_test = torch.randn(1, d)\n",
        "    ψ_test = psi(x_test)                      # (1, m)\n",
        "    Φ_test = phi(W_test)                      # (1, d, m)\n",
        "    y_approx = torch.bmm(Φ_test, ψ_test.unsqueeze(-1)).squeeze().numpy()\n",
        "    print(\"y_approx =\", y_approx)\n",
        "    print(\"y_true =\", gelu_tanh(W_test @ x_test.T))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c56_ml0DUySO",
        "outputId": "22962a13-7da6-4dbc-f09d-946a98575f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_approx = [-0.11181282  0.18113723]\n",
            "y_true = tensor([[[-0.1460],\n",
            "         [ 0.1667]]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-dc9e478d3b1f>:5: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  return 0.5 * x * (1 + np.tanh(np.sqrt(2/np.pi) * (x + 0.044715 * np.power(x, 3))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "juqg65s1ITaz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lisa: Biased Estimation Optimization"
      ],
      "metadata": {
        "id": "AcxB_jYvoTIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reference Point Z_bar**\n",
        "\n",
        "\n",
        "A common deterministic (and therefore typically biased) approximation is something like a firstorder Taylor expansion. Concretely, for:\n",
        "\n",
        "\n",
        "$$\n",
        "y=\\operatorname{GELU}(W x) \\quad \\in \\mathrm{R}^d\n",
        "$$\n",
        "we pick a reference point $\\bar{x}$ (or equivalently $\\bar{z}=W \\bar{x}$ ) and do\n",
        "\n",
        "\n",
        "$$\n",
        "\\operatorname{GELU}(W x) \\approx \\operatorname{GELU}(\\bar{z})+\\operatorname{diag}\\left(\\operatorname{GELU}^{\\prime}(\\bar{z})\\right)[W(x-\\bar{x})]\n",
        "$$\n",
        "\n",
        "\n",
        "We can write that in the form\n",
        "\n",
        "\n",
        "$$\n",
        "\\Phi(W) \\Psi(x)\n",
        "$$\n",
        "by letting (for each dimension $d$ ):\n",
        "- $\\Phi(W)=\\left[\\operatorname{diag}\\left(\\operatorname{GELU}^{\\prime}(\\bar{z})\\right) W, \\operatorname{GELU}(\\bar{z})\\right]_{\\text {, }}$\n",
        "- $\\Psi(x)=\\left[\\begin{array}{c}x-\\bar{x} \\\\ 1\\end{array}\\right]$.\n",
        "\n"
      ],
      "metadata": {
        "id": "qHItLzITyePc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "d = 10\n",
        "\n",
        "x = np.random.normal(loc=0, scale=1, size=(d, 1))\n",
        "print(\"Layer shape of x: \", x.shape)\n",
        "print(x)\n",
        "\n",
        "W = np.random.normal(loc=0, scale=1, size=(d, d))\n",
        "print(\"Layer shape of W: \", W.shape)\n",
        "print(W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBo3238K-7VD",
        "outputId": "fb59bb9a-9007-414f-dd91-4e00c4c0316a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer shape of x:  (10, 1)\n",
            "[[-0.54482853]\n",
            " [-0.63161671]\n",
            " [-0.91564961]\n",
            " [-1.61399943]\n",
            " [-0.32162195]\n",
            " [-0.99222462]\n",
            " [-0.43824675]\n",
            " [-1.00634214]\n",
            " [-0.67069234]\n",
            " [-0.52997316]]\n",
            "Layer shape of W:  (10, 10)\n",
            "[[ 0.15442335  0.3980553  -0.52444445 -0.98954088  0.20999811  0.71897845\n",
            "   0.02773517  0.64994208  0.60642394 -0.36017352]\n",
            " [-0.22911784  0.68378315 -0.54357769  0.70303585  0.67343318  0.56204901\n",
            "   2.0718752  -0.61541612 -0.57229049 -0.06937265]\n",
            " [-0.33748318  0.91634761  0.72224767  0.23208452 -0.19391651 -0.06156583\n",
            "  -0.64269339  0.97637855 -0.91726821  0.35681976]\n",
            " [-1.76898045 -1.70892249  1.19247607  0.46073594 -0.89124224 -0.88789947\n",
            "  -0.04999247 -0.6534811   0.28152786  1.34730197]\n",
            " [-1.03744554 -1.21432242 -1.41537019 -0.50120456 -0.21842279 -0.2192634\n",
            "   1.3374741  -0.21391763 -1.56546067  0.43102527]\n",
            " [-0.09136713  1.04181634  0.33211971  0.91217382 -1.77372231 -0.62776832\n",
            "  -0.93404803 -0.5788386  -0.03663755 -0.09564729]\n",
            " [ 1.08729511 -0.00797789 -0.1177749  -0.39806573  0.10057281 -1.26703629\n",
            "   0.37581151 -0.41216408 -0.72390825  0.47263072]\n",
            " [ 1.46470698  0.60407206  0.14269414  1.12025428 -0.47792797 -1.87571796\n",
            "  -1.35177148 -0.59309435 -0.60358935 -0.21174922]\n",
            " [-0.84238441 -0.13935025 -0.64438236 -0.61982896  0.3506893  -2.06647539\n",
            "  -0.42201822  1.52535123 -0.98730535 -0.07278492]\n",
            " [ 0.32715062 -0.95017431  0.49669688 -0.94156317 -0.98754721 -0.43438677\n",
            "  -0.02161017  1.50938872 -0.71060865 -0.55376587]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference_point_z_bar = np.matmul(W, x)\n",
        "print(\"reference_point_z_bar shape: \", reference_point_z_bar.shape)\n",
        "print(\"reference_point_z_bar: \", reference_point_z_bar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyJ1C9kd9Ld6",
        "outputId": "37bc8e14-5733-45a8-c789-d9cab1fb83df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reference_point_z_bar shape:  (10, 1)\n",
            "reference_point_z_bar:  [[ 0.07878448]\n",
            " [-1.58637833]\n",
            " [-1.58217787]\n",
            " [ 1.15197815]\n",
            " [ 4.17559271]\n",
            " [-0.12413107]\n",
            " [ 1.8729242 ]\n",
            " [ 0.60285136]\n",
            " [ 3.4256965 ]\n",
            " [ 1.49600314]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "**The Derivative of GELU (tanh approximation) is:**\n",
        "\n",
        "$\n",
        "\\frac{\\tanh\\left(\\frac{\\sqrt{2} \\left(\\frac{8943x^{3}}{200000} + x\\right)}{\\sqrt{\\pi}}\\right) + 1}{2} + \\frac{x \\left(\\frac{26829x^{2}}{200000} + 1\\right) \\operatorname{sech}^{2}\\left(\\frac{\\sqrt{2} \\left(\\frac{8943x^{3}}{200000} + x\\right)}{\\sqrt{\\pi}}\\right)}{\\sqrt{2} \\sqrt{\\pi}}\n",
        "$"
      ],
      "metadata": {
        "id": "KTCI--yFJf2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- $\\Phi(W)=\\left[\\operatorname{diag}\\left(\\operatorname{GELU}^{\\prime}(\\bar{z})\\right) W, \\operatorname{GELU}(\\bar{z})\\right]_{\\text {, }}$\n",
        "- $\\Psi(x)=\\left[\\begin{array}{c}x-\\bar{x} \\\\ 1\\end{array}\\right]$."
      ],
      "metadata": {
        "id": "z1T14EaGL9sB"
      }
    },
    {
      "source": [
        "#import sympy\n",
        "# Use sympy functions for symbolic calculations, including sympy.tanh and sympy.sqrt\n",
        "#f = 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * x**3)))\n",
        "#df_dx = sympy.diff(f, x)\n",
        "\n",
        "def sech(x):\n",
        "  #just sech(x)\n",
        "  return 1 / np.cosh(x)\n",
        "\n",
        "def df_dx(x):\n",
        "  df_dx = (np.tanh((np.sqrt(2) * ((8943 * x**3) / 200000 + x)) / np.sqrt(np.pi)) + 1) / 2 + (x * ((26829 * x**2) / 200000 + 1) * sech((np.sqrt(2) * ((8943 * x**3) / 200000 + x)) / np.sqrt(np.pi))**2) / (np.sqrt(2) * np.sqrt(np.pi))\n",
        "  return df_dx\n",
        "\n",
        "print(\"original equation: 0.5 * x * (1 + tanh(sqrt(2 /π) * (x + 0.044715 * x**3)))\" )\n",
        "print(\"\")\n",
        "print(\"shape of derivative equation output: \", df_dx(reference_point_z_bar).shape)\n",
        "print(\"derivative equation output: \", df_dx(reference_point_z_bar))\n",
        "\n",
        "#\n",
        "#print(\"\")\n",
        "#print(\"derivative at reference point: \", df_dx_at_reference_point_z_bar)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm49428APH5R",
        "outputId": "62a0c879-852b-4856-d4ba-4bd242f2d190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original equation: 0.5 * x * (1 + tanh(sqrt(2 /π) * (x + 0.044715 * x**3)))\n",
            "\n",
            "shape of derivative equation output:  (10, 1)\n",
            "derivative equation output:  [[ 0.5627304 ]\n",
            " [-0.12389785]\n",
            " [-0.12413379]\n",
            " [ 1.11175594]\n",
            " [ 1.00015044]\n",
            " [ 0.40146715]\n",
            " [ 1.09960235]\n",
            " [ 0.92704488]\n",
            " [ 1.00313472]\n",
            " [ 1.12783005]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phi = [np.matmul(np.diag(df_dx(reference_point_z_bar)), W), gelu_tanh(reference_point_z_bar)]\n",
        "print(\"diag: \", np.diag(df_dx(reference_point_z_bar)).shape)\n",
        "print(\"W: \", W.shape)\n",
        "\n",
        "psi = [x - reference_point_z_bar, 1]\n",
        "print(\"phi shape: \", phi.shape)\n",
        "print(\"phi: \", phi)\n",
        "print(\"psi shape: \", psi.shape)\n",
        "print(\"psi: \", psi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "jVamEGieNDeY",
        "outputId": "4268200e-04a6-46f0-c6c4-018e7321a573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 10 is different from 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-29e57309723b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mphi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_point_z_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgelu_tanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_point_z_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"diag: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_point_z_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mreference_point_z_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 10 is different from 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This concludes the biased section**"
      ],
      "metadata": {
        "id": "cR1RlDftIc1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jicheol: Unbiased estimation"
      ],
      "metadata": {
        "id": "deiVRpArp22G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: These get better with more attempts (e.g. Monte Carlo-based approximation)."
      ],
      "metadata": {
        "id": "pLJhmMvXqI0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Approximating GELU using Monte Carlo simulation of sample size alpha = N and 1D variable x**"
      ],
      "metadata": {
        "id": "6HbFiIVIDWQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GELU Interpretation\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "&\\begin{aligned}\n",
        "\\operatorname{GELU}(z) & =x \\Phi(x), x \\in \\mathbb{R} \\\\\n",
        "& =x \\cdot P(z \\leq x), Z \\sim N(0,1) \\\\\n",
        "& =x \\cdot E[1\\{z \\leq x\\}], \\text { where } 1(x)= \\begin{cases}1, & z \\leq x \\\\\n",
        "0, & z>x \\\\\\end{cases}\n",
        "& \\approx x \\cdot \\frac{1}{N} \\sum_{i=1}^N 1_{z_i \\leq x} \\end{aligned}\\\\\n",
        "&\\text { and as } N \\rightarrow \\infty \\text { this converges to } \\operatorname{GELU}(x)\n",
        "\\end{aligned}\n",
        "\\end{equation}"
      ],
      "metadata": {
        "id": "iutGqm6QKkEv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given W_x is interpreted as:\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "w_x=\n",
        "\\begin{bmatrix}\n",
        "    \\omega_{x_{1,1}} & \\omega_{x_{1,2}} & \\omega_{x_{1,3}} & \\dots  & \\omega_{x_{1,n}} \\\\\n",
        "    \\omega_{x_{2,1}} & \\omega_{x_{2,2}} & \\omega_{x_{2,3}} & \\dots  & \\omega_{x_{2,n}} \\\\\n",
        "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "    \\omega_{x_{d,1}} & \\omega_{x_{d,2}} & \\omega_{x_{d,3}} & \\dots  & \\omega_{x_{d,n}}\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "28vxqZ5bOyFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We want to find $\\Phi(\\omega)$ and $\\psi(x)$ s.t.**\n",
        "$$\n",
        "\\begin{array}{cl}\n",
        "f\\left(w_x\\right)_{i j}=\\left(w_x\\right)_{i j} \\cdot \\Phi\\left(\\left(w_x\\right)_{i j}\\right) & i=1, \\ldots R \\\\ & j =1, \\ldots D \\\\\n",
        "\\text { or } f\\left(w_x\\right)=w_x \\odot \\Phi\\left(w_x\\right) &\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "$ \\odot $ here is an elementwise product. total of RD elementwise approximations.\n"
      ],
      "metadata": {
        "id": "youdNmHLSN1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\\begin{aligned}\n",
        "\\therefore f\\left(w_x\\right)_{i j} & =\\operatorname{GELU}\\left(\\left(w_x\\right)_{i j}\\right) \\\\\n",
        "& \\approx \\frac{1}{N} \\sum\\left(w_x\\right)_{i j} \\cdot 1 z_k^{i j} \\leq\\left(w_x\\right)_{i j}, z_k^{(i j)} \\backsim N(0,1)\n",
        "\\end{aligned}"
      ],
      "metadata": {
        "id": "NYkPcW2z_z2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**So we would like to find a solution to accomodate W_x:**\n",
        "$$\n",
        "G\\left(w_x{(i, j)}\\right) \\approx \\frac{1}{\\sqrt{2 \\pi}} \\sum_{n=0}^{\\infty} \\frac{(-1)^n}{2^n n!(2 n+1)}\\left(w_x{(i,j)}\\right)^{2 n+1}\n",
        "$$"
      ],
      "metadata": {
        "id": "5Rs2c0MoASgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output is an unbiased estimator of the true value\n",
        "def gelu_MC(x, N):\n",
        "    success = 0\n",
        "    for _ in range(N):\n",
        "        z = np.random.normal(0, 1)\n",
        "        if z <= x:\n",
        "            success += 1\n",
        "    return (success / N) * x\n",
        "\n",
        "print(\"Monte Carlo approximation:\", gelu_MC(x,n)) #this value changes every time due to random sampling"
      ],
      "metadata": {
        "id": "ikn9Ev1rrUyB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "c15d1955-6f78-4acf-a7ab-73366d230841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'x' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e44806e8089d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msuccess\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Monte Carlo approximation:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgelu_MC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#this value changes every time due to random sampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    }
  ]
}